{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f2c12cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_obb.estimation import obb_estimate_pca, obb_estimate_dito\n",
    "import trimesh\n",
    "\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(12)\n",
    "\n",
    "def sample_spherical(npoints, ndim=3):\n",
    "    vec = np.random.randn(npoints, ndim).astype(np.float32)\n",
    "    vec /= np.linalg.norm(vec, axis=1)[:, None]\n",
    "    return vec\n",
    "\n",
    "rotation_matrix = trimesh.transformations.rotation_matrix(np.pi/4, [1, 0, 0])\n",
    "# points1 = rng.random((500, 3)).astype(np.float32) * np.array([1, 1, 1], dtype=np.float32)\n",
    "# points2 = rng.random((14, 3)).astype(np.float32) * np.array([1, 5, 2], dtype=np.float32)\n",
    "points3 = sample_spherical(15, 3) * np.array([2, 2, 1] + np.array([1.0, 0.0, 0.0], dtype=np.float32), dtype=np.float32)\n",
    "points3 = trimesh.transform_points(points3, rotation_matrix)\n",
    "points3 = points3.astype(np.float32)\n",
    "points = torch.nested.as_nested_tensor([torch.from_numpy(points3)], layout=torch.jagged)\n",
    "vertices_pca, basis_pca = obb_estimate_pca(points)\n",
    "vertices_dito, basis_dito = obb_estimate_dito(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "234c8b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9942, -0.0504,  0.0947],\n",
       "         [ 0.0404,  0.6421,  0.7655],\n",
       "         [-0.0994,  0.7649, -0.6364]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a195eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.9427, -0.3158, -0.1075],\n",
       "         [-0.0654, -0.4908,  0.8688],\n",
       "         [-0.3271, -0.8120, -0.4834]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_dito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3afb6084",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "canvas.is_closed() is deprecated, use canvas.get_closed() instead.\n",
      "Your scene does not contain any lights. Some objects may not be visible.\n",
      "Unrecognized present mode 1000361000\n",
      "Unrecognized present mode 1000361000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized present mode 1000361000\n"
     ]
    }
   ],
   "source": [
    "import pygfx as gfx\n",
    "import trimesh\n",
    "from rendercanvas.glfw import GlfwRenderCanvas\n",
    "\n",
    "_TRIS = [[1, 3, 0],\n",
    "         [4, 1, 0],\n",
    "         [0, 3, 2],\n",
    "         [2, 4, 0],\n",
    "         [1, 7, 3],\n",
    "         [5, 1, 4],\n",
    "         [5, 7, 1],\n",
    "         [3, 7, 2],\n",
    "         [6, 4, 2],\n",
    "         [2, 7, 6],\n",
    "         [6, 5, 4],\n",
    "         [7, 5, 6]]\n",
    "i = 0\n",
    "canvas = GlfwRenderCanvas(size=(1024, 768), max_fps=60, update_mode=\"continuous\")   \n",
    "scene = gfx.Scene()\n",
    "background = gfx.Background(None, gfx.BackgroundMaterial('white'))\n",
    "scene.add(background)\n",
    "\n",
    "vertices_pca_np = vertices_pca[i].cpu().numpy()\n",
    "print(vertices_pca_np.shape)\n",
    "vertices_dito_np = vertices_dito[i].cpu().numpy()\n",
    "points_np = points[i].cpu().numpy()\n",
    "\n",
    "\n",
    "points_geometry = gfx.Geometry(positions=points_np.astype(np.float32))\n",
    "pc = gfx.Points(points_geometry, material=gfx.PointsMaterial(size=10, color=(0, 0, 0, 1.0)))\n",
    "scene.add(pc)\n",
    "\n",
    "obb_geometry_pca = gfx.Geometry(positions=vertices_pca_np.squeeze().astype(np.float32), indices=np.array(_TRIS, dtype=np.int32))\n",
    "obb_pca = gfx.Mesh(obb_geometry_pca, gfx.MeshBasicMaterial(wireframe=True, color='cyan', wireframe_thickness=2))\n",
    "scene.add(obb_pca)\n",
    "\n",
    "obb_geometry_dito = gfx.Geometry(positions=vertices_dito_np.squeeze().astype(np.float32), indices=np.array(_TRIS, dtype=np.int32))\n",
    "obb_dito = gfx.Mesh(obb_geometry_dito, gfx.MeshBasicMaterial(wireframe=True, color='red', wireframe_thickness=2))\n",
    "scene.add(obb_dito)\n",
    "\n",
    "\n",
    "disp = gfx.Display(canvas=canvas)\n",
    "disp.show(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95333ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p0 -2.989874, 0.037348, 0.121857\n",
      "p1 2.993481, -0.096555, -0.026632\n",
      "furthest_index 0\n",
      "diff_norm_sq 35.840511\n",
      "i 0, testing cases\n",
      "i 0: best_val initial 47.688675\n",
      "i 0: e0 -0.999442, 0.022367, 0.024803\n",
      "i 0: n_vec -0.009402, 0.524201, -0.851543\n",
      "i 0: m0 -0.032048, -0.851301, -0.523698\n",
      "dlen span_e0 5.986695, span_n 1.699457, span_m0 3.695462\n",
      "i 0: q0 38.578018\n",
      "i 0: best_val 38.578018\n"
     ]
    }
   ],
   "source": [
    "from torch_obb.util import ensure_warp_available\n",
    "from torch_obb.estimation import prepare_vertices\n",
    "from torch_obb.kernels.estimation_utils import compute_obb_vertices\n",
    "from torch_obb.kernels.estimation_dito import NUM_SLAB_DIRS, SLAB_DIRS, best_obb_axes_from_base_triangle_kernel, BLOCK_SIZE, compute_obb_extents_jagged\n",
    "from typing import Optional\n",
    "import warp as wp\n",
    "\n",
    "def obb_estimate_dito_dbg(vertices_t: torch.Tensor,\n",
    "                          device: Optional[str] = None) -> torch.Tensor:\n",
    "    ensure_warp_available()\n",
    "    if device is None:\n",
    "        device = vertices_t.device\n",
    "\n",
    "    npoints_t = vertices_t.offsets().diff()\n",
    "    if (npoints_t < NUM_SLAB_DIRS * 2).any():\n",
    "        raise ValueError(f\"Each batch must have at least {NUM_SLAB_DIRS * 2} vertices.\")\n",
    "\n",
    "    slab_dirs_t = SLAB_DIRS.to(dtype=vertices_t.dtype, device=device)#.unsqueeze(1)\n",
    "\n",
    "    # operate directly on the non-jagged values and then convert back to jagged representations\n",
    "    slab_projs_t = torch.nested.nested_tensor_from_jagged(torch.inner(vertices_t.values(), slab_dirs_t), \n",
    "                                                          offsets=vertices_t.offsets(), \n",
    "                                                          jagged_dim=1)\n",
    "\n",
    "    min_proj_t, min_proj_arg_t = torch.min(slab_projs_t, dim=1)\n",
    "    max_proj_t, max_proj_arg_t = torch.max(slab_projs_t, dim=1)\n",
    "\n",
    "    # correct the indices for the offsets into the jagged array as torch nested does not support torch.gather directly\n",
    "    min_proj_arg_t += slab_projs_t.offsets()[:-1].unsqueeze(1)\n",
    "    max_proj_arg_t += slab_projs_t.offsets()[:-1].unsqueeze(1)\n",
    "\n",
    "    min_vert_t = vertices_t.values()[min_proj_arg_t]\n",
    "    max_vert_t = vertices_t.values()[max_proj_arg_t]\n",
    "\n",
    "    many_vertices_mask_t = npoints_t > NUM_SLAB_DIRS * 2\n",
    "    few_vertices_mask_t = ~many_vertices_mask_t\n",
    "    aabb_min_t = min_proj_t[:, :3]\n",
    "    aabb_max_t = max_proj_t[:, :3]\n",
    "\n",
    "    # device_wp = wp.device_from_torch(device)\n",
    "    # aabb_min_wp = wp.from_torch(aabb_min_t, dtype=wp.vec3f).to(device_wp)\n",
    "    # aabb_max_wp = wp.from_torch(aabb_max_t, dtype=wp.vec3f).to(device_wp)\n",
    "    # min_vert_wp = wp.from_torch(min_vert_t, dtype=wp.vec3f).to(device_wp)\n",
    "    # max_vert_wp = wp.from_torch(max_vert_t, dtype=wp.vec3f).to(device_wp)\n",
    "    # selected_vertices_wp = wp.from_torch(selected_vertices_t, dtype=wp.vec3f).to(device_wp)\n",
    "    # basis_wp = wp.zeros((vertices_t.shape[0], 3), dtype=wp.vec3f, device=device_wp)\n",
    "\n",
    "    # wp.launch_tiled(best_obb_axes_from_base_triangle_kernel, \n",
    "    #                 dim=[min_vert_t.shape[0]], \n",
    "    #                 inputs=[aabb_min_wp, aabb_max_wp, min_vert_wp, max_vert_wp, \n",
    "    #                         selected_vertices_wp, basis_wp], \n",
    "    #                 block_dim=BLOCK_SIZE,\n",
    "    #                 device=device_wp)\n",
    "\n",
    "    # basis_t = wp.to_torch(b    vertices_t, device = prepare_vertices(vertices, batch_offsets, device)asis_wp)\n",
    "\n",
    "    # centroids_t = torch.mean(vertices_t, dim=1)\n",
    "    # rotated_t_jagged = torch.bmm(vertices_t - centroids_t.unsqueeze(1), basis_t)\n",
    "    # min_extents_t = rotated_t_jagged.min(dim=1).values\n",
    "    # max_extents_t = rotated_t_jagged.max(dim=1).values\n",
    "\n",
    "    # # extent_local_t = max_extent_t - min_extent_t\n",
    "\n",
    "    # # min_extents_t, max_extents_t = compute_obb_extents_jagged(vertices_t, basis_t)\n",
    "    # extents_t = max_extents_t - min_extents_t\n",
    "    # center_local_t = (min_extents_t + max_extents_t) * 0.5\n",
    "    # centroids_t = centroids_t + torch.bmm(center_local_t.unsqueeze(1), basis_t.mT).squeeze(1)\n",
    "\n",
    "    # vertices_t = compute_obb_vertices(centroids_t, extents_t, basis_t)\n",
    "    # return vertices_t, basis_t\n",
    "    # use just the selected extreme points for large point clouds and fall back to \n",
    "    # all input vertices for small point clouds\n",
    "    selected_vertices_t = torch.empty(vertices_t.shape[0], NUM_SLAB_DIRS * 2, 3, \n",
    "                                      device=device, dtype=vertices_t.dtype)\n",
    "    selected_vertices_t[many_vertices_mask_t] = torch.cat((min_vert_t[many_vertices_mask_t], max_vert_t[many_vertices_mask_t]), dim=1)\n",
    "    batch_mask = few_vertices_mask_t.repeat_interleave(vertices_t.offsets().diff())\n",
    "    selected_vertices_t[few_vertices_mask_t] = vertices_t.values()[batch_mask].reshape(-1, NUM_SLAB_DIRS * 2, 3)\n",
    "\n",
    "    aabb_min_t = min_proj_t[:, :3]\n",
    "    aabb_max_t = max_proj_t[:, :3]\n",
    "\n",
    "    device_wp = wp.device_from_torch(device)\n",
    "    aabb_min_wp = wp.from_torch(aabb_min_t, dtype=wp.vec3f).to(device_wp)\n",
    "    aabb_max_wp = wp.from_torch(aabb_max_t, dtype=wp.vec3f).to(device_wp)\n",
    "    min_vert_wp = wp.from_torch(min_vert_t, dtype=wp.vec3f).to(device_wp)\n",
    "    max_vert_wp = wp.from_torch(max_vert_t, dtype=wp.vec3f).to(device_wp)\n",
    "    selected_vertices_wp = wp.from_torch(selected_vertices_t, dtype=wp.vec3f).to(device_wp)\n",
    "    basis_wp = wp.zeros((vertices_t.shape[0], 3), dtype=wp.vec3f, device=device_wp)\n",
    "\n",
    "    wp.launch_tiled(best_obb_axes_from_base_triangle_kernel, \n",
    "                    dim=[min_vert_t.shape[0]], \n",
    "                    inputs=[aabb_min_wp, aabb_max_wp, min_vert_wp, max_vert_wp, \n",
    "                            selected_vertices_wp, basis_wp], \n",
    "                    block_dim=BLOCK_SIZE,\n",
    "                    device=device_wp)\n",
    "\n",
    "    basis_t = wp.to_torch(basis_wp)\n",
    "    wp.synchronize()\n",
    "    print(\"basis_t\", basis_t)\n",
    "\n",
    "    min_extents_t, max_extents_t = compute_obb_extents_jagged(vertices_t, basis_t)\n",
    "    extents_t = max_extents_t - min_extents_t\n",
    "\n",
    "    print(\"min_extents_t\", min_extents_t)\n",
    "    print(\"max_extents_t\", max_extents_t)\n",
    "    print(\"extents_t\", extents_t)\n",
    "\n",
    "    # extent_local_t = max_extent_t - min_extent_t\n",
    "\n",
    "    # min_extents_t, max_extents_t = compute_obb_extents_jagged(vertices_t, basis_t)\n",
    "    center_local_t = (min_extents_t + max_extents_t) * 0.5\n",
    "    print(\"center_local_t\", center_local_t)\n",
    "    center_t = torch.bmm(center_local_t.unsqueeze(1), basis_t).squeeze(1)\n",
    "    #centroids_t = centroids_t + \n",
    "    print(\"center_t\", center_t)\n",
    "    vertices_t = compute_obb_vertices(center_t, extents_t, basis_t.mT)\n",
    "    return vertices_t, basis_t\n",
    "\n",
    "vertices_t, device = prepare_vertices(points)\n",
    "obb_vertices_t, basis_t = obb_estimate_dito(vertices_t, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "83d5c303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected_vertices [[-2.9898741   0.03734799  0.12185741]\n",
      " [ 0.03033754 -1.580308   -0.9092275 ]\n",
      " [ 0.09764951 -0.91442716 -1.5797487 ]\n",
      " [-2.2235081  -0.99000704 -0.90026516]\n",
      " [-2.5925367  -0.39307746  0.3175297 ]\n",
      " [-2.7081242   0.30593196 -0.3025362 ]\n",
      " [-2.0312033   1.061924    1.0176934 ]\n",
      " [ 2.9934807  -0.09655452 -0.02663192]\n",
      " [-0.21309438  1.5728798   1.0364574 ]\n",
      " [-0.26456386  0.96158034  1.5748404 ]\n",
      " [ 2.1768355   0.9276872   1.0113583 ]\n",
      " [ 2.827919    0.26411942 -0.20710038]\n",
      " [ 2.734769   -0.3736506   0.20131332]\n",
      " [ 2.1009917  -1.0343412  -0.9819188 ]]\n",
      "furthest_index 0\n",
      "p0 [-2.9898741   0.03734799  0.12185741]\n",
      "p1 [ 2.9934807  -0.09655452 -0.02663192]\n",
      "diff_norm 35.84051\n",
      "bestval initial 47.688675\n",
      "e0 [-0.99944216  0.02236668  0.02480322]\n",
      "n [-0.00940161  0.5242009  -0.8515428 ]\n",
      "m0 [-0.03204806 -0.8513009  -0.5236982 ]\n",
      "dlen0 [5.9866953 1.6994574 3.6954618]\n",
      "quality0 38.57802\n",
      "bestval 38.57802\n",
      "basis [[-0.99944216  0.02236668  0.02480322]\n",
      " [-0.00940161  0.5242009  -0.8515428 ]\n",
      " [-0.03204806 -0.8513009  -0.5236982 ]] 0\n",
      "bmin [-2.994631  -1.0728691 -1.9561174]\n",
      "bmax [2.992064  1.0771921 1.9525405]\n",
      "blen [5.9866953 2.1500611 3.908658 ]\n",
      "q [-0.00128353  0.0021615  -0.00178844]\n",
      "center [ 0.0013198   0.00262685 -0.00093585]\n"
     ]
    }
   ],
   "source": [
    "from torch_obb._estimation_old import oriented_bounding_box_dito_14\n",
    "points_numpy_dbg = points[0].cpu().numpy()\n",
    "obb_numpy_dbg = oriented_bounding_box_dito_14(points_numpy_dbg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "04950b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9994,  0.0224,  0.0248],\n",
       "         [-0.0094,  0.5242, -0.8515],\n",
       "         [-0.0320, -0.8513, -0.5237]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basis_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7af87103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.0657372 ,  1.0358657 ,  1.8637326 ],\n",
       "       [ 2.9404721 , -2.2915783 , -0.18322468],\n",
       "       [ 3.0455232 ,  2.1629295 ,  0.03286362],\n",
       "       [ 2.920258  , -1.1645144 , -2.0140936 ],\n",
       "       [-2.9176183 ,  1.1697681 ,  2.0122218 ],\n",
       "       [-3.0428834 , -2.157676  , -0.03473532],\n",
       "       [-2.9378324 ,  2.296832  ,  0.18135297],\n",
       "       [-3.0630975 , -1.030612  , -1.8656043 ]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obb_numpy_dbg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3353025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.0657,  1.0359,  1.8637],\n",
       "         [ 2.9405, -2.2916, -0.1832],\n",
       "         [ 3.0455,  2.1629,  0.0329],\n",
       "         [ 2.9203, -1.1645, -2.0141],\n",
       "         [-2.9176,  1.1698,  2.0122],\n",
       "         [-3.0429, -2.1577, -0.0347],\n",
       "         [-2.9378,  2.2968,  0.1814],\n",
       "         [-3.0631, -1.0306, -1.8656]]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obb_vertices_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86fe112f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "canvas.is_closed() is deprecated, use canvas.get_closed() instead.\n",
      "Your scene does not contain any lights. Some objects may not be visible.\n",
      "Unrecognized present mode 1000361000\n",
      "Unrecognized present mode 1000361000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized present mode 1000361000\n"
     ]
    }
   ],
   "source": [
    "import pygfx as gfx\n",
    "import trimesh\n",
    "from rendercanvas.glfw import GlfwRenderCanvas\n",
    "\n",
    "_TRIS = [[1, 3, 0],\n",
    "         [4, 1, 0],\n",
    "         [0, 3, 2],\n",
    "         [2, 4, 0],\n",
    "         [1, 7, 3],\n",
    "         [5, 1, 4],\n",
    "         [5, 7, 1],\n",
    "         [3, 7, 2],\n",
    "         [6, 4, 2],\n",
    "         [2, 7, 6],\n",
    "         [6, 5, 4],\n",
    "         [7, 5, 6]]\n",
    "i = 0\n",
    "canvas = GlfwRenderCanvas(size=(1024, 768), max_fps=60, update_mode=\"continuous\")   \n",
    "scene = gfx.Scene()\n",
    "background = gfx.Background(None, gfx.BackgroundMaterial('white'))\n",
    "scene.add(background)\n",
    "\n",
    "#selected_vertices_np = selected_vertices_t[i].cpu().numpy()\n",
    "points_np = points[i].cpu().numpy()\n",
    "\n",
    "\n",
    "points_geometry = gfx.Geometry(positions=points_np.astype(np.float32))\n",
    "pc = gfx.Points(points_geometry, material=gfx.PointsMaterial(size=10, color=(0, 0, 0, 1.0)))\n",
    "scene.add(pc)\n",
    "\n",
    "\n",
    "# selected_vertices_geometry = gfx.Geometry(positions=selected_vertices_np.astype(np.float32))\n",
    "# pc_selected = gfx.Points(selected_vertices_geometry, material=gfx.PointsMaterial(size=20, color=(1.0, 0, 0, 1.0)))\n",
    "# scene.add(pc_selected)\n",
    "obb_vertices_np = obb_vertices_t[i].cpu().numpy()\n",
    "\n",
    "obb_geometry_dbg = gfx.Geometry(positions=obb_numpy_dbg.squeeze().astype(np.float32), indices=np.array(_TRIS, dtype=np.int32))\n",
    "obb_dbg = gfx.Mesh(obb_geometry_dbg, gfx.MeshBasicMaterial(wireframe=True, color='cyan', wireframe_thickness=2))\n",
    "scene.add(obb_dbg)\n",
    "\n",
    "obb_geometry = gfx.Geometry(positions=obb_vertices_np.squeeze().astype(np.float32), indices=np.array(_TRIS, dtype=np.int32))\n",
    "obb = gfx.Mesh(obb_geometry, gfx.MeshBasicMaterial(wireframe=True, color='red', wireframe_thickness=2))\n",
    "scene.add(obb)\n",
    "\n",
    "disp = gfx.Display(canvas=canvas)\n",
    "disp.show(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b844d62e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "semap_mapping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
